{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, InputLayer\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import r2_score, mean_absolute_error\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # 1. Load and preprocess the data\n",
    "# df = pd.read_csv('delaney-processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['Minimum Degree', 'Molecular Weight', 'Number of H-Bond Donors', 'Number of Rings', 'Number of Rotatable Bonds', 'Polar Surface Area']\n",
    "# target = 'measured log solubility in mols per litre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[features]\n",
    "# y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # Split the data\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # Normalize the data\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Scaler | Equation | When to Use | Preserves Zero Mean? | Sensitivity to Outliers | Range After Scaling |\n",
    "|--------|----------|-------------|----------------------|-------------------------|---------------------|\n",
    "| StandardScaler | $ z = \\frac{(x - \\mu)}{\\sigma} $ | When features have different units or different variances. Most suitable for algorithms that assume zero-centered data. | Yes | No | Varies |\n",
    "| MinMaxScaler | $ z = \\frac{(x - \\text{min})}{\\text{max} - \\text{min}} $ | When you need values in a bounded interval. Scales the data to a specific range, typically [0, 1] or [-1, 1]. | No | Yes | [0, 1] or Custom |\n",
    "| MaxAbsScaler | $ z = \\frac{x}{\\max(\\|x\\|)} $ | Useful for zero-centered or sparse data. | Yes, if data is zero-centered | Yes | [-1, 1] |\n",
    "| RobustScaler | $ z = \\frac{(x - \\text{median})}{\\text{IQR}} $ | When the data contains many outliers. Uses median and the interquartile range for scaling. | No | No | Varies |\n",
    "| QuantileTransformer (uniform output) | Transforms features to follow a uniform distribution | When you want to transform features to follow a uniform distribution. Useful for non-linear data. | No | No | [0, 1] |\n",
    "| QuantileTransformer (normal output) | Transforms features to follow a normal distribution | When you want to transform features to follow a normal distribution. Useful for non-linear data. | No | No | Varies, but closer to normal distribution |\n",
    "| PowerTransformer | Applies a power transformation to each feature | Useful for stabilizing variance and making the data more Gaussian-like. | Yes | No | Varies, but closer to normal distribution |\n",
    "| Normalizer | $ z = \\frac{x}{\\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2}} $ | Each parameter vector $x$ is normalized individually. Used when only the angle between feature vectors matter. Not really a scaler, but a normalizer. | No | No | Norm 1 |\n",
    "\n",
    "### Notes:\n",
    "- \"Varies\" in the \"Range After Scaling\" column means that the range isn't fixed and depends on the data.\n",
    "- \"Norm 1\" means that the Euclidean norm of each data vector will be 1.\n",
    "- $ \\mu $ is the mean of the feature.\n",
    "- $ \\sigma $ is the standard deviation of the feature.\n",
    "- $ \\text{min} $ and $ \\text{max} $ are the minimum and maximum values of the feature, respectively.\n",
    "- $ \\text{IQR} $ is the interquartile range, $ \\text{Q3} - \\text{Q1} $, where $ \\text{Q3} $ and $ \\text{Q1} $ are the third and first quartiles, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Add dropout and regularization\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # 2. Define the model\n",
    "# model = Sequential()\n",
    "# model.add(InputLayer(input_shape=(6,)))  # Explicit input layer with 6 features\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(1))  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "# opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "# model.compile(optimizer=opt, loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # 3. Train the model\n",
    "# # history = model.fit(X_train_scaled, y_train, epochs=200, validation_data=(X_val_scaled, y_val), verbose=1, callbacks=[early_stopping])\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=200, validation_data=(X_val_scaled, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # 4. Evaluate the model\n",
    "# test_loss, test_mse = model.evaluate(X_test_scaled, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate R^2 and MAE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Test RMSE: {np.sqrt(test_mse)}\")\n",
    "print(f\"Test R^2: {r2}\")\n",
    "print(f\"Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "y_pred = y_pred.reshape(-1)\n",
    "\n",
    "# Create a dataframe to compare true and predicted values\n",
    "comparison_df = pd.DataFrame({'True_Values': y_test, 'Predicted_Values': y_pred})\n",
    "\n",
    "# Display the comparison dataframe\n",
    "print(comparison_df.head())\n",
    "\n",
    "# Plotting true vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='True_Values', y='Predicted_Values', data=comparison_df)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "# Residuals plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.residplot(x='True_Values', y='Predicted_Values', data=comparison_df, lowess=True)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals\n",
    "residuals = comparison_df['True_Values'] - comparison_df['Predicted_Values']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
